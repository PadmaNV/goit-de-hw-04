### **Question #1**

**_Чому при додаванні однієї проміжної дії nuek_processed.collect(), отримано аж на 3 Job більше?_**

#### **Answer #1**

Додання проміжної дії collect() створює додаткові Job у Spark, оскільки ця дія змінює спосіб, 
у який Spark обробляє запити:
1. Ледачі операції, не виконуються одразу та Actions виконують обчислення та повертають результат
2. Коли додано проміжну дію collect(), Spark завершує обчислення для поточної частини, виконує всі
   попередні трансформації, матеріалізує результат, і лише після цього продовжує наступну частину
   обчислень.
3. При виконанні nuek_processed.collect(), Spark виконує обчислення до цього моменту потім
   додається новий DAG для решти трансформацій (where("count>2"))
4. Spark додає додаткові Jobs через операції Shuffles та повторне розділення даних на партиції.
   У коді:
          - Repartition (2): Перерозподіляє дані, створюючи нові партиції.
          - GroupBy - Count: Викликає операцію Shuffles.
          - Два collect(): Завершують кожну частину DAG, примусово виконуючи Jobs.
   Таким чином, кожна операція додає кілька етапів (Stages), а виконання двох collect() спричиняє
   перерахунок DAG.

### **Висновок:** 
**Додавання проміжних collect() може збільшити час виконання, оскільки частини DAG виконуються
окремо та викликає зайве переміщення даних між вузлами**



### **Question #2**

**_Чому при додаванні однієї проміжної дії nuek_processed.collect(), отримано аж на 3 Job більше?_**

#### **Answer #2** 

Зменшення кількості **Job** при використанні `cache()` відбувається завдяки тому, що Spark зберігає в пам'яті (або на диску, залежно від конфігурації) результати обчислень до проміжної точки. Це дозволяє уникнути повторних обчислень для тих самих даних, які використовуються у кількох операціях.

### Розбір двох кодів:

---

#### **Код без `cache()`**
1. **Проблема**:
   - У цьому коді `nuek_processed` обчислюється двічі:
     - Перший раз при виконанні `nuek_processed.collect()`.
     - Другий раз після застосування фільтра `where("count > 2")` і виконання дії `collect()`.
   - Через відсутність кешування Spark кожного разу виконує всі попередні трансформації, включаючи читання файлу, фільтрацію, `groupBy`, і обчислення `count()`. Це призводить до дублювання обчислень і додаткових **Job**.

---

#### **Код із `cache()`**
1. **Що відбувається**:
   - Виклик `nuek_processed_cached.cache()` зберігає результати обчислень до цього моменту (включаючи `groupBy` і `count()`) у пам'яті (RAM) або на диску.
   - При подальших викликах, таких як `nuek_processed_cached.collect()` і `where("count > 2")`, Spark не повторно виконує весь попередній DAG, а використовує вже закешовані результати.
   
2. **Результат**:
   - Зменшення кількості **Job**, оскільки Spark уникає повторних обчислень.

---

### Головна причина зменшення Job:
- У Spark без `cache()` кожен виклик дії (`Action`) призводить до повного обчислення DAG, починаючи з початкових даних.
- З `cache()`, результати до цього моменту зберігаються, і всі подальші обчислення виконуються на вже оброблених даних, що значно зменшує обсяг роботи.

---

### Аналіз графіку DAG:
1. **Без `cache()`**:
   - Кожен виклик `collect()` або інша дія викликає повний перерахунок DAG (від читання файлу до групування та обчислення).
   - Це створює більше етапів (`Stages`) і збільшує кількість Job.

2. **З `cache()`**:
   - Після кешування обчислення до цього моменту не повторюються.
   - Наступні дії використовують кешовані результати, що зменшує кількість **Job** і етапів DAG.

---

### Висновок:
Використання `cache()` дозволяє оптимізувати виконання коду в Spark:
- Зменшує кількість Job і етапів DAG.
- Уникає повторного виконання тих самих трансформацій.
- Підвищує продуктивність за рахунок використання пам'яті (RAM) або диску.
